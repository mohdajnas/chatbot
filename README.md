
# ğŸ™ï¸ Voice Chatbot with Ollama & LLaMA3.2

This Python project enables real-time voice interaction with a local LLM (LLaMA3.2) using [Ollama](https://ollama.com/). It captures your voice, converts it to text, sends it to a local language model, and reads the response aloud.

---

## ğŸ› ï¸ Features

- ğŸ¤ Voice input via microphone (using SpeechRecognition)
- ğŸ§  Text generation via LLaMA3.2 with Ollama
- ğŸ”Š Spoken replies using pyttsx3 (offline TTS)
- ğŸ—¨ï¸ Local, private, and open-source
- âŒ Say "exit" to quit the session

---

## ğŸ“¦ Requirements

### Python Packages

Install dependencies with pip:

```bash
pip install speechrecognition pyttsx3
````

### Ollama Setup

Make sure you have [Ollama](https://ollama.com) installed and running. Then pull the model:

```bash
ollama pull llama3.2
```

> âœ… Ollama runs the language model **locally** â€” no API keys required!

---

## â–¶ï¸ Usage

1. Connect your microphone
2. Run the script:

```bash
python voice_chatbot.py
```

3. Speak when prompted.
4. Say **"exit"** to stop.

---

## ğŸ’» Source Code

```python
import subprocess
import speech_recognition as sr
import pyttsx3

def speak(text):
    engine = pyttsx3.init()
    engine.say(text)
    engine.runAndWait()

def listen():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("ğŸ¤ Speak now...")
        audio = recognizer.listen(source)
    try:
        return recognizer.recognize_google(audio)
    except sr.UnknownValueError:
        print("âŒ Could not understand audio")
        return ""
    except sr.RequestError as e:
        print(f"âŒ STT request error: {e}")
        return ""

def query_ollama(prompt):
    process = subprocess.Popen(
        ["ollama", "run", "llama3.2"],
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True
    )
    stdout, stderr = process.communicate(input=prompt)

    if stderr.strip():
        print("[stderr]:", stderr.strip())
    if stdout.strip():
        return stdout.strip()
    return "âš ï¸ No response received."

def interact_with_ollama():
    print("ğŸ™ï¸ Voice mode activated (say 'exit' to quit).")
    while True:
        user_input = listen()
        if not user_input:
            continue
        print(f"You: {user_input}")

        if user_input.lower() == "exit":
            print("ğŸ‘‹ Exiting...")
            break

        response = query_ollama(user_input)
        print(f"Ollama: {response}")
        speak(response)

if __name__ == "__main__":
    interact_with_ollama()
```

---

## ğŸ“ File Structure

```
voice_chatbot.py       # Main chatbot script
README.md              # This file
```

---

## ğŸ“ Notes

* A working microphone is required.
* Google STT (used by `SpeechRecognition`) needs internet access.
* pyttsx3 works offline using your OS's default TTS engine.
* Ollama runs models locally â€” ideal for privacy-focused applications.

---

## ğŸ“œ License

MIT License

```

Let me know if you'd like a version that uses Whisper for offline transcription or adds GUI support.
```
